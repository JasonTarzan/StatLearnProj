{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings: Google Pretrained Word2Vec Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports and Set Options\n",
    "\n",
    "import csv  # for slang\n",
    "import os\n",
    "import re  # regex\n",
    "import string  # punct\n",
    "from pprint import pprint\n",
    "\n",
    "import emoji  # for emoji\n",
    "import gensim\n",
    "import keras\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords  # stopwords\n",
    "from nltk.stem import PorterStemmer  # stemming\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import svm, tree\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
    "                              GradientBoostingClassifier,\n",
    "                              RandomForestClassifier, RandomForestRegressor,\n",
    "                              StackingClassifier)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import (accuracy_score, auc, average_precision_score,\n",
    "                             brier_score_loss, classification_report,\n",
    "                             confusion_matrix, f1_score, fbeta_score,\n",
    "                             make_scorer, plot_precision_recall_curve,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score, roc_auc_score, roc_curve)\n",
    "from sklearn.model_selection import (GridSearchCV, KFold, RandomizedSearchCV,\n",
    "                                     cross_val_score, train_test_split)\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC  # \"Support vector classifier\"\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning Class\n",
    "\n",
    "- Implemented as a sklearn `Estimator` with (obligatory) `fit` and `transform` methods. \n",
    "- Additional `transform_no_stem` method returns cleaned texts without stemming, producing appropriate input for Word2Vec, which expects complete word tokens (as appeared in its training corpus). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Class\n",
    "\n",
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def remove_mentions(self, input_text):\n",
    "        '''\n",
    "        Remove mentions, like @Mplamplampla\n",
    "        '''\n",
    "        return re.sub(r'@+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        '''\n",
    "        Remove the urls mention in a tweet\n",
    "        '''\n",
    "        input_text  = ' '.join([w for w in input_text.split(' ') if '.com' not in w])\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        input_text = emoji.demojize(input_text)\n",
    "        input_text = input_text.replace('_','')\n",
    "        input_text = input_text.replace(':','')\n",
    "        return input_text\n",
    "    \n",
    "    def possessive_pronouns(self, input_text):\n",
    "        '''\n",
    "        Remove the possesive pronouns, because otherwise after tokenization we will end up with a word and an s\n",
    "        Example: government's --> [\"government\", \"s\"]\n",
    "        '''\n",
    "        return input_text.replace(\"'s\", \"\")\n",
    "    \n",
    "    def characters(self, input_text):\n",
    "        '''\n",
    "        Remove special and redundant characters that may appear on a tweet and that don't really help in our analysis\n",
    "        '''\n",
    "        input_text = input_text.replace(\"\\r\", \" \") # Carriage Return\n",
    "        input_text = input_text.replace(\"\\n\", \" \") # Newline\n",
    "        input_text = \" \".join(input_text.split()) # Double space\n",
    "        input_text = input_text.replace('\"', '') # Quotes\n",
    "        return input_text\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        '''\n",
    "        Remove punctuation and specifically these symbols '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "        '''\n",
    "        punct = string.punctuation # string with all the punctuation symbols '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    \n",
    "    def remove_digits(self, input_text):\n",
    "        '''\n",
    "        Remove numbers\n",
    "        '''\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        '''\n",
    "        Convert all the sentences(words) to lowercase\n",
    "        '''\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        '''\n",
    "        Remove stopwords (refers to the most common words in a language)\n",
    "        '''\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        '''\n",
    "        Reduce the words to their stem\n",
    "        '''\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def encode_decode(self, input_text):\n",
    "        '''\n",
    "        Remove weird characters that are result of encoding problems\n",
    "        '''\n",
    "        return  \" \".join([k.encode(\"ascii\", \"ignore\").decode() for k in input_text.split(\" \")])\n",
    "    \n",
    "    \n",
    "    def translator(self, input_text):\n",
    "        '''\n",
    "        Transform abbrevations to normal words\n",
    "        Example: asap --> as soon as possible\n",
    "        '''\n",
    "        input_text = input_text.split(\" \")\n",
    "        j = 0\n",
    "        for _str in input_text:\n",
    "            # File path which consists of Abbreviations.\n",
    "            fileName = r\"slang.txt\"\n",
    "            # File Access mode [Read Mode]\n",
    "            accessMode = \"r\"\n",
    "            with open(fileName, accessMode) as myCSVfile:\n",
    "                # Reading file as CSV with delimiter as \"=\", so that \n",
    "                # abbreviation are stored in row[0] and phrases in row[1]\n",
    "                dataFromFile = csv.reader(myCSVfile, delimiter=\"=\")\n",
    "                # Removing Special Characters.\n",
    "                _str = re.sub('[^a-zA-Z0-9-_.]', '', _str)\n",
    "                for row in dataFromFile:\n",
    "                    # Check if selected word matches short forms[LHS] in text file.\n",
    "                    if _str.upper() == row[0]:\n",
    "                        # If match found replace it with its appropriate phrase in text file.\n",
    "                        input_text[j] = row[1]\n",
    "                myCSVfile.close()\n",
    "            j = j + 1\n",
    "        \n",
    "        return(' '.join(input_text))\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = (X.apply(self.translator)\n",
    "                    .apply(self.remove_mentions)\n",
    "                    .apply(self.remove_urls)\n",
    "                    .apply(self.emoji_oneword)\n",
    "                    .apply(self.possessive_pronouns)\n",
    "                    .apply(self.remove_punctuation)\n",
    "                    .apply(self.remove_digits)\n",
    "                    .apply(self.encode_decode)\n",
    "                    .apply(self.characters)\n",
    "                    .apply(self.to_lower)\n",
    "                    .apply(self.remove_stopwords)\n",
    "                    .apply(self.stemming))\n",
    "        return clean_X\n",
    "    \n",
    "    def transform_no_stem(self, X, **transform_params):\n",
    "        clean_X = (X.apply(self.translator)\n",
    "                    .apply(self.remove_mentions)\n",
    "                    .apply(self.remove_urls)\n",
    "                    .apply(self.emoji_oneword)\n",
    "                    .apply(self.possessive_pronouns)\n",
    "                    .apply(self.remove_punctuation)\n",
    "                    .apply(self.remove_digits)\n",
    "                    .apply(self.encode_decode)\n",
    "                    .apply(self.characters)\n",
    "                    .apply(self.to_lower)\n",
    "                    .apply(self.remove_stopwords))\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec via the `gensim.downloader` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('https://github.com/anilkeshwani/StatLearnProj/raw/master/Iason/climate_change_tweets_sample-2020-05-16-17-57.csv')\n",
    "\n",
    "# NOT RUN. For consistency across methods with other input datasets, these usernames have *not* been removed. \n",
    "# Optional: Remove errant rows; usernames '318', '54' or '96'\n",
    "# tweets.drop(tweets[tweets.username.isin(['318', '54', '96'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning\n",
    "\n",
    "- No stemming\n",
    "- Removal of one errant row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "ct.fit(tweets.text)\n",
    "tweets[\"text_clean\"] = ct.transform_no_stem(tweets.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>username</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_clean_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>Economic recovery and national climate pledges...</td>\n",
       "      <td>0</td>\n",
       "      <td>economic recovery national climate pledges mus...</td>\n",
       "      <td>economic recovery national climate pledges mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>In this difficult time, it’s hard to connect w...</td>\n",
       "      <td>0</td>\n",
       "      <td>difficult time hard connect natural world eart...</td>\n",
       "      <td>difficult time hard connect natural world eart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>43</td>\n",
       "      <td>69</td>\n",
       "      <td>The decision to postpone # COP26, is unavoidab...</td>\n",
       "      <td>0</td>\n",
       "      <td>decision postpone cop unavoidable collective p...</td>\n",
       "      <td>decision postpone cop unavoidable collective p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>Japan - the world’s fifth largest emitter of g...</td>\n",
       "      <td>0</td>\n",
       "      <td>japan worlds fifth largest emitter greenhouse ...</td>\n",
       "      <td>japan worlds fifth largest emitter greenhouse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>How can countries include # NatureBasedSolutio...</td>\n",
       "      <td>0</td>\n",
       "      <td>countries include naturebasedsolutions climate...</td>\n",
       "      <td>countries include climate plans new guidance o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1              username user_handle        date retweets favorites                                               text  label                                         text_clean                                   text_clean_known\n",
       "0           0             0  WWF Climate & Energy  climateWWF  2020-04-28       11        22  Economic recovery and national climate pledges...      0  economic recovery national climate pledges mus...  economic recovery national climate pledges mus...\n",
       "1           1             1  WWF Climate & Energy  climateWWF  2020-04-22        6        16  In this difficult time, it’s hard to connect w...      0  difficult time hard connect natural world eart...  difficult time hard connect natural world eart...\n",
       "2           2             2  WWF Climate & Energy  climateWWF  2020-04-01       43        69  The decision to postpone # COP26, is unavoidab...      0  decision postpone cop unavoidable collective p...  decision postpone cop unavoidable collective p...\n",
       "3           3             3  WWF Climate & Energy  climateWWF  2020-03-30       24        30  Japan - the world’s fifth largest emitter of g...      0  japan worlds fifth largest emitter greenhouse ...  japan worlds fifth largest emitter greenhouse ...\n",
       "4           4             4  WWF Climate & Energy  climateWWF  2020-03-30       22        40  How can countries include # NatureBasedSolutio...      0  countries include naturebasedsolutions climate...  countries include climate plans new guidance o..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>username</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_clean_known</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, Unnamed: 0.1, username, user_handle, date, retweets, favorites, text, label, text_clean, text_clean_known]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View rows with null `text_clean` value\n",
    "\n",
    "tweets.loc[(tweets.text_clean.isnull()), :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null `text_clean` value\n",
    "\n",
    "tweets = tweets.loc[(~tweets.text_clean.isnull()), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets.to_csv(\"clean_tweets_no_stemming.csv\") # save once processed\n",
    "tweets = pd.read_csv(\"clean_tweets_no_stemming.csv\") # read in instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add clean text field containing only words known to pretrained Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of text_clean_known entries which are null: 0\n",
      "Count of text_clean_known entries which empty: # 3\n",
      "After cleaning:\n",
      "Count of text_clean_known entries which are null: 0\n",
      "Count of text_clean_known entries which empty: 0\n"
     ]
    }
   ],
   "source": [
    "tweets[\"text_clean_known\"] = tweets.text_clean.apply(func=lambda tweet: ' '.join([word for word in tweet.split() \\\n",
    "                                                                               if word in wv.vocab]))\n",
    "print(f\"Count of text_clean_known entries which are null: {sum(tweets.text_clean_known.isnull())}\")\n",
    "print(f\"Count of text_clean_known entries which empty: \\\n",
    "{sum(tweets.text_clean_known.apply(func=lambda x: x.strip() == ''))}\")\n",
    "\n",
    "# Remove both rows with either null or empty `text_clean_known` entries\n",
    "\n",
    "tweets = tweets.loc[(~tweets.text_clean_known.isnull()), :]\n",
    "tweets = tweets.loc[~tweets.text_clean_known.apply(func=lambda x: x.strip() == ''), ]\n",
    "\n",
    "print(\"After cleaning:\", end=\"\\n\")\n",
    "print(f\"Count of text_clean_known entries which are null: {sum(tweets.text_clean_known.isnull())}\")\n",
    "print(f\"Count of text_clean_known entries which empty: {sum(tweets.text_clean_known.apply(func=lambda x: x.strip() == ''))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Tweet Vectors\n",
    "\n",
    "#### Implement Tweet Vectorizer: Word2VectorizeTweet\n",
    "\n",
    "- Retrieves vector for words (where possible; although input here is clean, there is a fallback for unrecognised word keys)\n",
    "- **Takes (component-wise; arithmetic) mean of word vectors to calculate a _tweet vector_**\n",
    "- Tracks number of words for which vector entries exist in the (pre-trained) vocabulary (used for average)\n",
    "\n",
    "NB Could have done this by precalcuting number of token per tweet document given that we have clean and known (to Word2Vec) input, but I kept the function as it was before, when I was using input that optionally contained _unknown_ words. Not sure if the speed improvement is critical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word2VectorizeTweet(tweet):\n",
    "    tweet_vector = np.zeros(shape=(300,), dtype=\"float32\")\n",
    "    n_vectorizable = 0\n",
    "    for word in tweet.split():\n",
    "        try:\n",
    "#             print(f\"Adding {word} to word representation\")\n",
    "            tweet_vector = np.add(tweet_vector, wv.get_vector(word))\n",
    "            n_vectorizable += 1\n",
    "        except KeyError:\n",
    "            print(f\"Could not vectorize {word}\")\n",
    "    return (tweet_vector/n_vectorizable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"wv\"] = tweets.text_clean_known.apply(func=Word2VectorizeTweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word2Vec-Representation Input Dataset - Vector Mean Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00756226  0.06903076 -0.01115723  0.185083   -0.16228637  0.01247559\n",
      "   0.05341492 -0.07486572  0.04592896  0.10591812 -0.02705688 -0.11100464\n",
      "  -0.03353882 -0.00517578 -0.15960693  0.1170166   0.02597656  0.15979004\n",
      "   0.04359131 -0.06125488 -0.01443481  0.02495117  0.11098633  0.04191894\n",
      "   0.02767887  0.04990234 -0.08166198  0.01254883  0.04807129 -0.02866821\n",
      "  -0.03339844 -0.0260376  -0.08784332 -0.04694519  0.06231689 -0.05767517\n",
      "   0.04456787  0.08453369  0.07069091  0.01975098  0.05698242 -0.02724304\n",
      "   0.0932373   0.06208496 -0.01950684 -0.0621582  -0.00041504  0.08579101\n",
      "  -0.2020874   0.04884949  0.03145752  0.01223144 -0.07353516 -0.17507324\n",
      "  -0.03920899  0.02390747 -0.06101685 -0.13779297  0.01408691 -0.1177002\n",
      "  -0.01579971  0.07027588 -0.13205567 -0.12597656  0.01966553 -0.04987793\n",
      "  -0.00275269  0.07321777 -0.10512695  0.00593262  0.03122559  0.04464569\n",
      "   0.07122803 -0.00961304 -0.15692139 -0.04655151  0.08242188  0.20649414\n",
      "  -0.0019043   0.09255371  0.05478706  0.00766907 -0.00367432 -0.0445549\n",
      "  -0.02194824 -0.01582642 -0.1121582   0.11691894  0.06274414  0.12924805\n",
      "   0.0810318  -0.00117188 -0.06521606 -0.04764404 -0.00779419 -0.14980468\n",
      "   0.03280335 -0.08046875  0.08762207 -0.06467285 -0.04200592  0.02930298\n",
      "   0.01099853  0.03947754 -0.02680206 -0.05149536 -0.01608887 -0.05587158\n",
      "   0.03967895 -0.09371796 -0.00291748  0.00525818  0.00977783 -0.0315465\n",
      "   0.11700439  0.02750244  0.1121582  -0.0408844   0.07923584  0.13166504\n",
      "  -0.03813706 -0.0116087  -0.09664307  0.14914551  0.01785889 -0.00719414\n",
      "  -0.03265991 -0.04915772  0.0015625   0.04951172  0.04235535  0.00524902\n",
      "  -0.04714966  0.03211059 -0.01918945 -0.07189941  0.0531311  -0.03000488\n",
      "  -0.02626953  0.02558594  0.0982666  -0.11450195  0.04696045 -0.0576416\n",
      "   0.10698242 -0.00935974  0.00682983 -0.07559204 -0.04891358 -0.00720215\n",
      "   0.03305664 -0.08873291 -0.0434021   0.03686218  0.04916763 -0.11726074\n",
      "  -0.00165405  0.00574951 -0.07725219 -0.00233459 -0.01781006  0.14565125\n",
      "   0.03719483  0.00281982  0.03334961 -0.12714843 -0.012677   -0.09289551\n",
      "   0.06098633  0.02897949 -0.14695701  0.02526855 -0.01835937 -0.06192017\n",
      "  -0.06379394  0.0228302   0.03170166 -0.08173828 -0.04734077  0.01038208\n",
      "  -0.11051331 -0.0217041   0.05632324 -0.01842041  0.00288391 -0.00820312\n",
      "   0.00187988  0.08984375  0.00873413 -0.01077271 -0.03127442 -0.01534576\n",
      "   0.07191925  0.03208618  0.04885864 -0.00190125  0.03293457  0.04594726\n",
      "   0.02225342 -0.15073243 -0.00643311  0.03776855 -0.06002045  0.03774719\n",
      "   0.01428223  0.03173828  0.05177002 -0.07802124 -0.02946777 -0.01576843\n",
      "  -0.02442627  0.07741699 -0.01334229 -0.0013916  -0.04957275  0.03138733\n",
      "   0.11182861  0.01936035 -0.02262878  0.02961426 -0.06186829 -0.02069397\n",
      "  -0.08691406 -0.02921143 -0.02758789 -0.06671143  0.15452881 -0.05625\n",
      "   0.00677719  0.09741821  0.01074829  0.07751465  0.05986328 -0.05966191\n",
      "   0.07559814  0.00672607 -0.06199341 -0.09958496  0.14642334 -0.07345276\n",
      "   0.12484131 -0.01951904 -0.01245117 -0.09017334  0.00370483  0.01176453\n",
      "  -0.12420654  0.06170349 -0.07390442  0.01055908 -0.05759277  0.09151821\n",
      "   0.05170899  0.1263916   0.07612304 -0.09084473  0.10113525  0.04118652\n",
      "  -0.01259766 -0.03307724  0.01913147  0.00030518 -0.03543701  0.08093262\n",
      "   0.07248382  0.11750488 -0.03881836 -0.10770264 -0.1656845  -0.0637207\n",
      "   0.02886658  0.1184021   0.09759521  0.09072113 -0.02497787 -0.08408203\n",
      "  -0.06801148 -0.02265625 -0.00339355  0.02410889  0.00754395  0.01621857\n",
      "   0.05605469 -0.00325012  0.00508118  0.01574097 -0.0491333  -0.06477661\n",
      "   0.02468262  0.08115234 -0.07006836 -0.00116577  0.06698914  0.02908936\n",
      "  -0.0306694   0.04721812  0.02189941  0.01544189  0.07306824  0.01334763]\n",
      " [ 0.08021376  0.08034939 -0.01611328  0.16368273 -0.11949328  0.03979492\n",
      "   0.00148858 -0.08153619  0.07683139  0.13167317 -0.11707899 -0.07712131\n",
      "  -0.09085083  0.01491695 -0.08473714  0.01570638  0.0159573   0.04581027\n",
      "   0.05541992 -0.10583835 -0.00738525  0.08233304  0.01126099  0.03464084\n",
      "   0.06518555 -0.04520416 -0.07405599  0.03336928  0.04121907  0.03905169\n",
      "  -0.01620822 -0.02997504 -0.07846408 -0.09056261  0.01630317 -0.05084907\n",
      "  -0.00092909  0.00249566  0.19912042  0.00254991  0.08185492  0.01601156\n",
      "   0.01698134  0.05234782 -0.03102621 -0.0730523  -0.06218804  0.10555013\n",
      "  -0.06388346  0.11082628 -0.12344021  0.0838623  -0.13534206 -0.14503309\n",
      "   0.03595649  0.08445231  0.02091471 -0.21978082 -0.01196628 -0.12314013\n",
      "  -0.07984754  0.02950033  0.01295302 -0.12852648  0.09063043 -0.02843263\n",
      "  -0.03257073  0.1957533   0.03130426  0.10686578 -0.02549913  0.07880995\n",
      "   0.13267687 -0.0370263  -0.1107254  -0.05388239  0.13052028  0.12420315\n",
      "  -0.0963406   0.03559865  0.03027344  0.02357313  0.08009169 -0.04829576\n",
      "   0.07971869  0.03529188 -0.05335829  0.12630208 -0.1140408   0.17306858\n",
      "   0.09863281 -0.04945204 -0.12537977 -0.05622016  0.06966146 -0.01904297\n",
      "   0.00315687  0.01615397  0.21101888 -0.01302083  0.00893148 -0.08463541\n",
      "   0.01324463  0.02275933  0.05699327 -0.00837877 -0.10335287  0.0183665\n",
      "   0.12688531 -0.0980089  -0.03738064  0.05989583 -0.13552772  0.0625\n",
      "  -0.03586833 -0.01764594  0.03683811  0.0409139   0.05724759  0.08874512\n",
      "  -0.05608113 -0.12044271 -0.08144125  0.08189562 -0.12852648 -0.01044379\n",
      "  -0.01135932 -0.02349175 -0.05801053  0.02445051 -0.04294841  0.05939399\n",
      "  -0.00212267 -0.04600694  0.04287381  0.06700982  0.10144721 -0.00777414\n",
      "  -0.12980144  0.00404188  0.19970703 -0.15544806 -0.04032389 -0.01963976\n",
      "   0.1044515   0.06139798  0.04866536 -0.06106906  0.08989801 -0.04351129\n",
      "   0.1451823  -0.11322699 -0.02189806  0.07769097  0.07263523 -0.13172743\n",
      "   0.03733995 -0.0419871  -0.0602417  -0.0809733  -0.04523383  0.02360026\n",
      "  -0.0316391  -0.04465061  0.01976861 -0.07367621  0.01140001 -0.05819363\n",
      "  -0.00682237 -0.0331014  -0.03793504  0.01754634  0.03474257  0.02118598\n",
      "   0.03800456  0.03431532 -0.08976237 -0.07494439 -0.09204441  0.01204427\n",
      "  -0.13216145 -0.0964152   0.08208551 -0.10028754  0.09845649 -0.03304503\n",
      "  -0.05665164 -0.00465224  0.05608622  0.16362847 -0.05889893  0.00474718\n",
      "   0.17229716 -0.04985894 -0.06833225  0.10234918 -0.00754123 -0.10466851\n",
      "   0.00089518 -0.11313205  0.00514052  0.10386149 -0.04060194  0.02203539\n",
      "   0.04562039  0.0388048   0.2445204  -0.10321469 -0.11686198  0.04263814\n",
      "  -0.01802572 -0.01738824  0.0345103   0.09100977 -0.04399533 -0.00070869\n",
      "   0.06947157 -0.01380751 -0.08410645  0.00546604  0.01237657  0.02448188\n",
      "   0.06313748 -0.03464932 -0.05299208  0.05592177  0.14941406 -0.09074572\n",
      "   0.07244703  0.08364529 -0.0274014   0.08203973  0.11005317 -0.13447401\n",
      "   0.06871203  0.00965034 -0.00284068  0.00223117  0.17409939 -0.11848959\n",
      "   0.18028429  0.04584418  0.0006307  -0.06151666 -0.05696614  0.10504828\n",
      "   0.02856445  0.06178114  0.03664822 -0.02045356 -0.0376926   0.03793674\n",
      "  -0.04244656  0.06624349  0.12561035 -0.060574    0.13993327 -0.10248481\n",
      "  -0.0612047   0.01293945 -0.04694621 -0.0176256  -0.05727302  0.08784315\n",
      "   0.01017253  0.15939671 -0.07021078 -0.03497992 -0.02864583 -0.11325412\n",
      "  -0.07800293  0.08197021  0.03693305 -0.01920573 -0.01466878 -0.06049432\n",
      "  -0.23224555 -0.02262709  0.0789388   0.09288364  0.05366347 -0.03727637\n",
      "   0.10811276  0.01737128  0.02989366 -0.00232697  0.03309716 -0.06298828\n",
      "   0.08736166 -0.01015218 -0.03097873  0.02596029 -0.02516005  0.1338908\n",
      "   0.03285048 -0.04648166 -0.00740051 -0.01302083  0.1267361   0.03181966]\n",
      " [ 0.06314087  0.0743103  -0.00581915  0.04242915 -0.0559193   0.02617715\n",
      "   0.01297968 -0.08728027  0.07131264  0.0221946   0.02211137 -0.07828036\n",
      "  -0.07103383  0.0310447  -0.1535922   0.01834037 -0.03018466  0.13019909\n",
      "   0.03855757 -0.04316434 -0.02980735  0.08608177 -0.00937913 -0.03594416\n",
      "   0.01080435 -0.03775683 -0.05628551 -0.00104315  0.03910966 -0.01471259\n",
      "  -0.047648   -0.02638661  0.01167436 -0.04118763 -0.00135179  0.01037459\n",
      "   0.02563338 -0.03384191  0.06081876  0.03168279  0.043628    0.02529768\n",
      "   0.01519775  0.00426743 -0.06718306 -0.04859508 -0.00885148  0.01627142\n",
      "  -0.03821078  0.02164875  0.03663497  0.00683871 -0.03388838 -0.05626817\n",
      "  -0.02761611 -0.04212501 -0.1011408  -0.07878251  0.01973378 -0.09829989\n",
      "  -0.09622955  0.07204091 -0.10747112 -0.07128074 -0.00982666 -0.02761286\n",
      "  -0.00954229  0.08579597 -0.015625    0.04796809 -0.04179244  0.01299563\n",
      "   0.08056779  0.02981567 -0.09912387 -0.04430736  0.0394731   0.1310404\n",
      "  -0.07603316  0.03794445  0.03705874 -0.0030906   0.01305875  0.01678016\n",
      "   0.00757261 -0.04037753 -0.10377156  0.08509133  0.00979337  0.0497603\n",
      "   0.11228666 -0.02414773 -0.03453324 -0.06242787 -0.07237937 -0.06192294\n",
      "   0.05781278 -0.02155928  0.05657959 -0.07861605 -0.02127474 -0.04900464\n",
      "  -0.00199751  0.08645665 -0.06242787 -0.05815281 -0.00839233 -0.1086835\n",
      "   0.06934747 -0.08998663 -0.03415472 -0.04573198 -0.07625718 -0.01579064\n",
      "   0.07836775  0.01405976  0.05728149 -0.02220293  0.03657116  0.11500389\n",
      "  -0.07075986  0.03054948 -0.09047473  0.06104625 -0.04044966 -0.03733687\n",
      "  -0.04957164 -0.05092378 -0.0699019   0.034729   -0.02247204 -0.1096122\n",
      "  -0.04656167 -0.07000663  0.0051214   0.01502852  0.03400213  0.00052435\n",
      "  -0.01407693  0.04967984  0.02970193 -0.1613381   0.00359969 -0.00889587\n",
      "   0.01048417  0.00349704 -0.02036632 -0.05238065 -0.00518244  0.00820645\n",
      "   0.05468195 -0.05912365 -0.02351796  0.02300748 -0.01489084 -0.04006542\n",
      "  -0.01388134 -0.07452185 -0.0037925  -0.09517045 -0.04554055  0.05720659\n",
      "  -0.02826483 -0.01707458 -0.00983776 -0.02690402  0.05742784 -0.04086442\n",
      "   0.08837891 -0.09173584 -0.06085743  0.04649214 -0.02014507 -0.08686412\n",
      "   0.05055792 -0.04219541  0.04606074 -0.04583706 -0.08206541  0.06452127\n",
      "  -0.15123402 -0.08095897  0.07814997 -0.03279599 -0.01014293 -0.05532993\n",
      "  -0.06719138  0.13778687  0.03120006  0.09765971 -0.03497314 -0.02103355\n",
      "   0.04750061 -0.0100819  -0.04573267  0.05443989  0.04327393  0.00640037\n",
      "   0.01125266 -0.13717651 -0.05541437  0.05097545  0.05739247  0.00440008\n",
      "  -0.02997104  0.04869773  0.06033603 -0.02615911 -0.00890558 -0.03859225\n",
      "  -0.01342669  0.03614391  0.06847589  0.07827568 -0.04376498  0.05756309\n",
      "   0.02284171  0.04178411 -0.03077282  0.06621205  0.00575326 -0.01627419\n",
      "   0.01670283  0.00695731  0.02322249 -0.05927623  0.13777576  0.02178366\n",
      "   0.02215472  0.04070767 -0.01287703  0.01543912  0.05856254  0.00174852\n",
      "   0.04574862 -0.0480416   0.03599132 -0.09663183  0.07387751 -0.05592624\n",
      "   0.07635637 -0.02051059 -0.02004728 -0.0687783   0.00619784  0.03422928\n",
      "  -0.00972401 -0.03046278  0.00976562  0.00594746 -0.09073431  0.06992271\n",
      "   0.00833685  0.0587831   0.0791085  -0.09694195  0.1710094  -0.01697124\n",
      "  -0.10216176  0.00414345 -0.05476796 -0.03112654 -0.00415317  0.12188166\n",
      "   0.06087286  0.12895341 -0.04323509 -0.02080744 -0.1601285  -0.0093578\n",
      "  -0.00799561  0.09629545  0.04850284 -0.08167891  0.017867   -0.01598427\n",
      "  -0.07165805 -0.1125627  -0.0335083  -0.0081801  -0.00128798 -0.03469849\n",
      "   0.13331674  0.04850006 -0.00195659  0.00178112 -0.06694447 -0.08210616\n",
      "   0.07686684  0.02762396 -0.22377153  0.01732289 -0.06936923  0.02967626\n",
      "   0.0065918   0.04142128 -0.05702626  0.01270225  0.10925848  0.00998514]] (14404, 300)\n",
      "\n",
      "[[-4.22241203e-02  7.58239776e-02 -1.38111115e-02  1.32812500e-01\n",
      "  -8.64257850e-03 -3.68057266e-02  3.20526138e-02 -7.71728531e-02\n",
      "   1.56799313e-02  9.73876938e-02 -8.58398452e-02 -9.43725556e-02\n",
      "  -5.21240234e-02 -2.51096729e-02 -9.07104462e-02  9.31030288e-02\n",
      "   5.26086800e-02  1.89392090e-01  5.22338860e-02 -9.40551758e-02\n",
      "   5.15319817e-02  9.06448364e-02 -9.29870643e-03  6.48925751e-02\n",
      "   8.42895545e-03  8.79951492e-02 -8.41369629e-02  1.55761719e-01\n",
      "   1.20239258e-01  2.77347560e-03 -6.70242310e-02 -8.09326172e-02\n",
      "  -5.92102036e-02 -1.22900389e-01  1.38183590e-02 -2.11791992e-02\n",
      "  -1.05957035e-02  0.00000000e+00  1.03983305e-01 -5.37109387e-04\n",
      "   1.57226566e-02 -7.02575669e-02 -5.89721687e-02  7.66601562e-02\n",
      "  -4.00756821e-02 -5.36376946e-02  1.39282225e-02 -1.33544924e-02\n",
      "  -1.34956360e-01  3.20068374e-02 -2.24975590e-02 -1.80297848e-02\n",
      "  -3.47167961e-02 -1.73339841e-03  1.65771488e-02 -1.22253420e-02\n",
      "  -9.46411118e-02 -4.86816391e-02 -1.74316410e-02 -1.12780765e-01\n",
      "  -8.57360810e-02 -4.22363263e-03 -8.12499970e-02 -5.64453118e-02\n",
      "   8.08654800e-02 -8.61816388e-03 -9.74121131e-03  6.38244599e-02\n",
      "  -2.55371090e-02  6.09008782e-02 -8.51440430e-02  8.59313980e-02\n",
      "   1.70751959e-01  3.39126587e-02 -1.20600127e-01 -8.93554688e-02\n",
      "   1.25048831e-01  1.42919928e-01 -4.87075821e-02  4.56542969e-02\n",
      "   1.21289060e-01  3.76220718e-02  3.29589844e-03  2.57873535e-03\n",
      "  -1.44348145e-02 -2.18505859e-02 -8.51074234e-02  3.46649177e-02\n",
      "  -3.13232429e-02  1.37939453e-01  5.96435554e-02 -1.23089597e-01\n",
      "  -1.04858398e-01 -4.26269546e-02 -2.30041500e-02  2.27844231e-02\n",
      "   1.67816170e-02 -1.02362059e-01  1.92846686e-01 -3.11279297e-02\n",
      "  -2.45384220e-02 -2.76092533e-02 -3.33129875e-02  8.59619156e-02\n",
      "  -6.38916045e-02  5.96801750e-02 -8.92944336e-02 -4.18457016e-02\n",
      "   7.47985858e-03 -1.60046384e-01  1.98608395e-02  3.93066416e-03\n",
      "  -1.03613280e-01 -3.87542732e-02  1.16230585e-01  7.36846915e-03\n",
      "   2.14355476e-02 -3.57210152e-02  1.64746091e-01  1.22586206e-01\n",
      "  -1.31604001e-01 -8.57421905e-02 -5.88439927e-02  1.36547849e-01\n",
      "  -2.40539555e-02 -3.41148376e-02  2.12463383e-02  6.07666001e-02\n",
      "   7.72705069e-03  3.95996086e-02 -6.19361885e-02 -1.29699707e-02\n",
      "  -6.21154793e-02 -3.68408188e-02 -1.75659172e-02 -4.82788077e-03\n",
      "   7.15942401e-03 -1.59545895e-02 -4.54223640e-02  2.19268799e-02\n",
      "   1.60758972e-01 -1.42639158e-02 -1.13342283e-02  2.11181631e-03\n",
      "   8.47778320e-02 -8.85742158e-02  8.50341767e-02 -8.44421387e-02\n",
      "   6.41845688e-02  1.89208984e-02  1.19335935e-01 -6.41876236e-02\n",
      "   3.27758789e-02 -2.89978031e-02  8.64746124e-02 -1.69775397e-01\n",
      "   1.98974609e-02  5.60302753e-03 -4.78576645e-02 -1.03881836e-01\n",
      "  -9.50195342e-02  8.02490264e-02  1.76773069e-03  1.69433597e-02\n",
      "  -3.73046882e-02  4.64904793e-02  1.04003906e-01 -5.86273186e-02\n",
      "   3.90258804e-02 -3.83850113e-02 -6.57455474e-02  1.02294926e-02\n",
      "   7.42187500e-02 -6.32812530e-02  3.17382812e-02  2.80395504e-02\n",
      "   1.34399412e-02 -5.46844490e-02 -1.29907221e-01 -6.07910147e-03\n",
      "  -9.91699249e-02 -9.63439941e-02  3.13964859e-02 -6.24267571e-02\n",
      "   7.33917207e-02  4.91149910e-02 -6.19850159e-02  6.82556182e-02\n",
      "   6.90628067e-02  7.61596709e-02 -7.04895034e-02  2.56958008e-02\n",
      "   1.59988403e-02  1.58447269e-02 -1.03643797e-01  1.03405759e-01\n",
      "  -5.91552742e-02 -1.39770508e-02  4.24957275e-02 -7.19238296e-02\n",
      "  -4.05776985e-02  8.43444839e-02 -1.78100578e-02 -2.54837032e-02\n",
      "   6.70166034e-03  4.99389656e-02  1.25048831e-01  3.23303230e-02\n",
      "  -2.38342285e-02  9.02664214e-02 -1.71752926e-02 -1.05712889e-02\n",
      "  -3.42483521e-02  2.53536217e-02  4.76074230e-04  3.11889648e-02\n",
      "   9.19189453e-02 -5.16845696e-02 -1.50720209e-01  2.87353508e-02\n",
      "  -3.05328369e-02  2.79968269e-02  3.00292973e-03 -1.93786618e-04\n",
      "  -6.13525398e-02 -2.95410156e-02  4.23828140e-02  4.39453125e-02\n",
      "   8.29956084e-02 -8.50830041e-03 -1.39404293e-02 -8.68377648e-03\n",
      "   1.11083984e-01 -1.25439450e-01  8.05397034e-02  5.68237295e-03\n",
      "   4.46166992e-02  6.66503888e-03  4.37049866e-02 -4.95605469e-02\n",
      "   1.28662109e-01  3.87695320e-02  1.17431637e-02 -5.12023941e-02\n",
      "  -4.90783677e-02  7.13745132e-02  1.79443357e-03  7.73559585e-02\n",
      "   7.91625958e-03 -6.70654327e-02 -8.34960956e-03  4.91699204e-02\n",
      "  -7.32574463e-02  9.78698768e-03  9.37866196e-02 -5.50170913e-02\n",
      "   1.00286864e-01 -4.47998047e-02 -5.87768573e-03  2.88513191e-02\n",
      "   2.71606434e-04  2.98461923e-03 -3.36868279e-02  4.28344719e-02\n",
      "   5.81054688e-02  1.31604001e-01 -4.94415276e-02 -3.88702378e-02\n",
      "  -3.05175781e-02 -1.30151361e-01 -7.18994141e-02  6.56249970e-02\n",
      "  -6.70166034e-03 -3.69934067e-02  4.30725105e-02  1.29241939e-03\n",
      "  -4.19799797e-02  6.84051514e-02  1.23046879e-02  9.90893096e-02\n",
      "  -5.90087883e-02 -3.06640621e-02  8.12622085e-02  6.81732148e-02\n",
      "   7.89206475e-02 -8.83789081e-03 -1.86279304e-02 -3.89343277e-02\n",
      "   5.02197258e-02  2.65563969e-02 -7.99438506e-02 -2.50244141e-03\n",
      "   8.88427719e-02  4.63195816e-02  5.98876961e-02 -3.23120132e-02\n",
      "  -2.74856575e-02  4.95727547e-02  5.49987778e-02  3.55590805e-02]\n",
      " [-2.87597664e-02  1.48071293e-02  5.64819351e-02  1.10961914e-01\n",
      "  -9.72412080e-02 -1.00952145e-02  1.79168694e-02 -7.94311538e-02\n",
      "   1.10382080e-01  2.29492188e-02 -4.84451279e-02 -1.57568365e-01\n",
      "   7.17773428e-03 -5.81079498e-02 -9.82788056e-02  9.57031250e-02\n",
      "   4.19067368e-02  8.56506377e-02  1.21551510e-02 -5.35766594e-02\n",
      "   3.48937996e-02 -4.06494131e-03  5.14648445e-02 -5.11474609e-02\n",
      "  -6.41937256e-02 -5.59844961e-03 -8.25073272e-02  7.02514648e-02\n",
      "   8.58398452e-02 -6.81127533e-02 -1.35888666e-01 -3.99536118e-02\n",
      "  -4.00634781e-02 -4.46899422e-02  1.37207033e-02 -1.81335453e-02\n",
      "   3.12622078e-02  3.93367782e-02  6.57623261e-02  6.59790039e-02\n",
      "  -2.25830078e-03 -3.37158218e-02  6.33300766e-02  7.22534209e-02\n",
      "  -1.12724304e-03 -9.40673798e-02  4.32495102e-02  5.06713875e-02\n",
      "  -6.16180412e-02  4.31884751e-02 -2.72064214e-03  2.83813477e-02\n",
      "  -2.32055672e-02 -5.09826653e-02 -5.65948477e-03 -2.46276855e-02\n",
      "  -7.22290054e-02 -8.50585923e-02 -2.10433956e-02 -8.46557617e-02\n",
      "  -1.16333012e-02  1.23535153e-02 -9.25598145e-02 -5.58959953e-02\n",
      "  -1.04187010e-02 -9.65942368e-02 -5.77392578e-02  6.10809326e-02\n",
      "   7.30590820e-02  1.15966797e-01 -2.70874016e-02  7.39807114e-02\n",
      "   1.08032227e-01  2.42553707e-02 -1.19491577e-01 -8.02734345e-02\n",
      "   1.01321414e-01  1.29064947e-01 -4.38842773e-02  3.84521484e-02\n",
      "   1.42150875e-02  1.28173828e-02  1.67114250e-02 -7.75390640e-02\n",
      "   1.02532960e-01 -2.42919917e-03 -8.14392120e-02  9.84287262e-02\n",
      "  -5.10864239e-03 -2.09533684e-02  3.68652344e-02 -4.49218750e-02\n",
      "  -1.37384027e-01  2.27539055e-02 -5.05249016e-02  2.42370609e-02\n",
      "   3.56445322e-03  3.53393555e-02  1.54159546e-01 -1.42333983e-02\n",
      "  -2.28393562e-02 -1.14017487e-01 -3.54797356e-02  2.13134773e-02\n",
      "  -1.76161770e-02  3.89739983e-02 -2.04272464e-01  2.17041019e-02\n",
      "   7.00927749e-02 -9.44030732e-02 -3.69873047e-02 -4.51660156e-02\n",
      "  -1.43310549e-02 -3.25820930e-02  1.09570310e-01 -5.35766594e-02\n",
      "  -1.66992191e-02 -8.02917480e-02  5.43666855e-02  1.08544923e-01\n",
      "  -7.10815415e-02 -5.86547852e-02 -8.60107392e-02  7.75695816e-02\n",
      "   2.13378910e-02 -6.64001480e-02 -6.18225113e-02 -2.00927742e-02\n",
      "   1.69677734e-02  8.32519494e-03 -6.30493164e-02  1.10961916e-02\n",
      "  -4.30358872e-02  1.49536133e-02 -6.06750473e-02  1.12402342e-01\n",
      "  -7.24914521e-02 -4.06677239e-02 -2.02636723e-03  1.47094727e-02\n",
      "   1.51660159e-01 -1.55578613e-01  2.15087887e-02  2.53417976e-02\n",
      "   1.04809567e-01 -4.40429673e-02  3.58093269e-02 -6.72424287e-02\n",
      "   1.00531004e-01  7.50732422e-03  1.59374997e-01 -3.09082028e-02\n",
      "   1.65649410e-02 -1.50268553e-02  6.68884292e-02 -1.41979977e-01\n",
      "   4.87792976e-02 -2.24063396e-02 -5.93994148e-02 -4.85229492e-02\n",
      "   5.49011212e-03  1.08276367e-01 -2.41699209e-03  7.17285126e-02\n",
      "  -2.16796882e-02  3.20800766e-02  5.38940448e-03  2.75115971e-03\n",
      "  -8.25195312e-02  1.04852296e-01 -6.35299683e-02  2.76977532e-02\n",
      "   4.23339829e-02 -1.77368168e-02 -2.88085938e-02 -3.08288578e-02\n",
      "   3.56887802e-02 -1.27175137e-01 -7.99804702e-02  4.15649414e-02\n",
      "  -4.36035171e-02 -4.26269546e-02  3.20770256e-02  8.82095322e-02\n",
      "   8.22753906e-02  6.30859360e-02 -1.47631839e-01  2.54394524e-02\n",
      "   2.14920044e-02  5.35034165e-02 -2.70080566e-02  3.13079841e-02\n",
      "   1.03500364e-02 -2.16064453e-02  7.42187491e-03  3.99536118e-02\n",
      "  -4.81918342e-02 -1.78906247e-01  7.68798813e-02 -1.25073239e-01\n",
      "  -1.40136722e-02  6.60156235e-02 -1.17126461e-02 -1.33743286e-02\n",
      "   8.76159668e-02  1.49475094e-02  7.15515167e-02  5.93749993e-02\n",
      "  -1.11669920e-01 -3.75884995e-02 -1.37390140e-02  7.81677216e-02\n",
      "  -7.85522442e-03  5.80448136e-02  1.29913334e-02 -4.46350090e-02\n",
      "   6.06933609e-02 -5.86914048e-02 -6.98669404e-02  8.30993615e-03\n",
      "  -6.95587173e-02  7.25708017e-03  3.34136970e-02  7.30834976e-02\n",
      "  -5.04150391e-02 -1.08935550e-01  9.03564468e-02  3.83911133e-02\n",
      "   4.79309075e-02  2.28210445e-02 -1.62536614e-02 -3.26293930e-02\n",
      "   2.41699219e-02 -3.66821280e-03  7.13745132e-02 -2.60559078e-02\n",
      "   5.91827407e-02 -2.96142586e-02  1.16394043e-01 -8.07739273e-02\n",
      "   5.36865219e-02  3.72680649e-02 -7.73883834e-02 -5.61523438e-02\n",
      "  -6.51550293e-02  2.20825188e-02 -5.95092773e-03  1.34086609e-01\n",
      "   3.89938359e-03 -1.21496581e-01  1.48223881e-02  3.78662124e-02\n",
      "  -1.89239495e-02  9.61517319e-02  1.72412112e-01 -6.23291023e-02\n",
      "   1.84826657e-01  2.88513191e-02 -2.40783691e-02 -2.10144036e-02\n",
      "   2.98156729e-03 -2.65075676e-02  5.16235344e-02  3.31603996e-02\n",
      "   8.78906250e-02  1.78881839e-01 -9.18579102e-02 -4.30419929e-02\n",
      "  -1.33117680e-02 -1.33544922e-01  4.36889641e-02  9.82421860e-02\n",
      "  -7.99560547e-03  5.62744141e-02 -3.91265862e-02 -3.25439461e-02\n",
      "  -1.44689947e-01 -9.92950425e-02 -2.90466305e-02  8.14819336e-02\n",
      "   2.47558597e-02 -5.12817390e-02  8.89282208e-03  1.04867555e-01\n",
      "   5.97656257e-02  4.33349609e-03  3.77944931e-02 -1.21008299e-01\n",
      "   8.17016587e-02  1.15789793e-01 -9.41040069e-02  8.59497041e-02\n",
      "   4.45098877e-02  6.12915047e-02 -5.33164963e-02 -4.51660156e-03\n",
      "  -1.57897957e-02  1.51977539e-02  2.92968750e-03  3.44238291e-03]\n",
      " [ 6.76602423e-02  4.23417538e-02 -1.57387480e-02  6.47638515e-02\n",
      "  -6.66226447e-02  5.48055805e-02  2.46380884e-02 -9.98979062e-02\n",
      "   1.16910070e-01  6.97687343e-02 -4.80485409e-02 -7.27483556e-02\n",
      "   1.28080193e-02  5.90043515e-02 -3.30144726e-02  6.68113008e-02\n",
      "   5.34224063e-02  1.73023567e-01 -5.39148487e-02 -6.90307617e-02\n",
      "  -2.71717422e-02  8.55268985e-02  5.85937500e-02  5.40937930e-02\n",
      "   3.82468477e-02 -1.05202414e-01 -1.33883387e-01  8.20978358e-02\n",
      "  -2.17618067e-02  3.81483585e-02  6.96910499e-03 -4.63534258e-02\n",
      "   4.60541472e-02  1.72511023e-02  6.27330467e-02  3.64990234e-02\n",
      "   2.36372519e-02  2.51806434e-02  4.02332656e-02  2.80539766e-02\n",
      "   1.30263582e-01 -5.61301485e-02  3.20323594e-02  6.34921715e-02\n",
      "  -1.85768828e-02 -4.78765331e-02  3.23153399e-02 -1.63643584e-02\n",
      "  -2.41810195e-02 -4.36318144e-02 -1.05257900e-02  3.13831680e-02\n",
      "  -6.01473711e-02 -2.22389922e-02  5.54407276e-02  4.94495742e-02\n",
      "  -6.09408282e-02 -5.19353710e-02  4.68583545e-03 -3.81858125e-02\n",
      "  -1.26287285e-02  5.55197969e-02 -1.51844367e-01 -4.07049023e-02\n",
      "  -1.52232781e-01  1.17187500e-01  4.50938828e-02  5.38108125e-02\n",
      "  -1.51478164e-02  2.89084688e-02  2.66390722e-02  1.02982959e-02\n",
      "   5.40216602e-02 -6.15012422e-02 -1.51234016e-01 -9.57606956e-02\n",
      "   9.90919676e-03  1.42223015e-01  1.06428668e-01  9.03986171e-02\n",
      "   2.51076445e-02 -4.65365313e-02  9.56920311e-02 -5.73508516e-02\n",
      "  -1.86989526e-03 -6.77268282e-02 -1.00785688e-01  1.01580530e-01\n",
      "   4.73799258e-02  2.69886367e-02  8.37846249e-02 -3.74422930e-02\n",
      "  -7.33032227e-02 -5.71510987e-03  5.72620751e-03 -1.05524234e-01\n",
      "   6.39260039e-02  2.60786572e-03  8.76090303e-02 -3.36525664e-02\n",
      "  -1.36982314e-02 -4.50134277e-02 -5.36693223e-02  6.00974336e-02\n",
      "  -6.03249297e-02 -3.82413007e-02 -4.48996797e-02  1.77140674e-03\n",
      "  -3.64546338e-03 -3.95549424e-02 -1.48703833e-03 -3.74311954e-02\n",
      "   3.19602266e-02 -2.56569609e-02  1.32390797e-01 -7.03901798e-02\n",
      "   9.36168358e-02  4.67140898e-02  2.09960938e-02  6.67993352e-02\n",
      "  -4.62674238e-02  4.37788526e-03  1.93204004e-02  8.50719139e-02\n",
      "  -7.56503046e-02 -7.48346522e-02 -8.06357618e-03 -8.41841251e-02\n",
      "  -2.35484727e-02  5.69014102e-02 -1.09730117e-01 -9.22296718e-02\n",
      "  -3.10058594e-02  4.01777774e-02  4.18479219e-02 -3.83356251e-02\n",
      "   7.04040527e-02  3.60856503e-02 -3.68652344e-02  9.81278811e-03\n",
      "   1.05823867e-01 -1.11416904e-02  5.46653047e-02 -4.39009219e-02\n",
      "   9.93208494e-04  1.82661582e-02 -5.05149141e-02 -3.81011963e-02\n",
      "   4.74094041e-02 -4.15039062e-03  1.31414235e-01  7.02514648e-02\n",
      "  -5.39717227e-02  8.47833790e-03 -4.60316055e-02 -6.29660860e-02\n",
      "  -3.20157129e-03 -2.26606894e-02 -8.48444179e-02 -8.88893828e-02\n",
      "  -4.32794727e-03  5.54865040e-02  4.60926406e-02  5.77059649e-02\n",
      "   1.85435899e-02 -1.12374043e-02  5.10475859e-02 -3.05619668e-02\n",
      "   1.75808985e-02  5.13805039e-02 -7.01571405e-02  4.37511085e-03\n",
      "   8.69584531e-02 -6.63008243e-02  1.18796611e-02 -1.47705078e-02\n",
      "  -2.24692598e-02 -7.88629726e-02 -9.18301695e-04  6.78877383e-02\n",
      "  -6.18896484e-02 -1.24778055e-01  7.13112578e-02  2.98850313e-02\n",
      "  -3.42684649e-02 -8.85980800e-02 -5.65241016e-02  3.41630429e-02\n",
      "   9.63467658e-02 -3.71204726e-02  4.98379804e-02 -3.43378223e-02\n",
      "  -3.66363525e-02 -3.42906616e-03 -4.96576466e-02  3.25594805e-02\n",
      "  -7.36231133e-02 -6.31214455e-02 -8.02778751e-02 -1.51134148e-01\n",
      "   3.72425430e-02  7.78975040e-02 -6.28884062e-02  1.44861396e-02\n",
      "   3.69762070e-02 -4.94884141e-02 -5.20075001e-02  1.86504016e-03\n",
      "   1.21279629e-02 -6.90945685e-02 -2.99294218e-02  2.40367539e-02\n",
      "  -3.35804336e-02  1.32945672e-01 -1.17180564e-01  1.07199932e-02\n",
      "   1.24358088e-01  5.26677929e-02 -8.56378749e-02  1.00974344e-01\n",
      "   1.49785820e-02  2.37149317e-02 -6.31214455e-02  8.62870663e-02\n",
      "  -2.13623047e-02 -7.49400780e-02  2.01360527e-02  3.97283398e-03\n",
      "   2.96741836e-02  7.02181756e-02 -3.54114883e-02  6.57265410e-02\n",
      "   6.02638945e-02 -3.41769122e-02  9.03653204e-02 -1.25559028e-02\n",
      "   5.44877490e-03 -1.07860215e-01  7.17357323e-02  4.37566601e-02\n",
      "   6.94482997e-02  1.70010645e-02  3.19824219e-02 -7.58327171e-02\n",
      "  -2.15287637e-02  1.06489703e-01 -1.39493076e-02  5.59779070e-02\n",
      "   6.03693165e-03 -5.57417423e-02 -8.82679299e-02  8.87839571e-02\n",
      "   1.12127133e-01  5.86381406e-02  6.09241836e-02 -3.71424928e-02\n",
      "   1.47061437e-01  5.94593398e-02 -1.19107336e-01  1.34388320e-02\n",
      "   6.04525488e-03 -6.03027344e-02 -4.81130444e-02  4.80513135e-03\n",
      "   3.29256915e-02  1.32945672e-01 -2.26107519e-02 -7.23433048e-02\n",
      "  -8.50830078e-02 -4.72745039e-02  1.82550598e-03  8.31430629e-02\n",
      "   1.60217285e-02  7.07341954e-02  8.11545625e-02 -3.68652344e-02\n",
      "  -1.36191621e-01 -7.89406523e-02 -1.67014375e-02  2.55903769e-02\n",
      "   3.50008868e-02 -1.23468570e-01 -8.18530023e-02  9.46409032e-02\n",
      "   1.28173828e-02 -9.08979923e-02 -7.75035545e-02 -3.63658555e-02\n",
      "   6.32213280e-02 -2.68526953e-02 -1.21931598e-01  5.15691601e-02\n",
      "  -3.05619668e-02 -1.37162646e-02 -9.21075977e-03  1.46956006e-02\n",
      "   1.10834293e-01  1.22084180e-02  5.55732027e-02  1.15238540e-02]] (3601, 300)\n",
      "\n",
      "7780    1\n",
      "8792    1\n",
      "2607    0\n",
      "Name: label, dtype: int64 (14404,)\n",
      "\n",
      "10509    1\n",
      "14316    1\n",
      "6254     0\n",
      "Name: label, dtype: int64 (3601,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_train, w2v_test, Y_train, Y_test = train_test_split(np.array(tweets.wv.tolist()), tweets.label, \n",
    "                                                    test_size=0.2, random_state=17, \n",
    "                                                    shuffle=True) # explicit default\n",
    "\n",
    "[print(dat[:3], dat.shape, end=\"\\n\"*2) for dat in [w2v_train, w2v_test, Y_train, Y_test]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaled versions of input datasets\n",
    "\n",
    "mas = MaxAbsScaler()\n",
    "w2v_train_scaled = mas.fit_transform(w2v_train)\n",
    "w2v_test_scaled = mas.transform(w2v_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "rf_clf.fit(w2v_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9997917245209664\n",
      "Out-of-Bag Score: 0.8166481532907526\n",
      "Cross-validated accuracy : [0.83859771 0.82610205 0.81291218 0.83130857 0.82743056]\n",
      "Mean CV accuracy : 0.827\n",
      "Test set score : 0.8442099416828659\n"
     ]
    }
   ],
   "source": [
    "rf_clf_cv_score = cross_val_score(rf_clf, w2v_train, Y_train)\n",
    "\n",
    "print(f\"Training Set Accuracy: {rf_clf.score(w2v_train, Y_train)}\")\n",
    "print(f\"Out-of-Bag Score: {rf_clf.oob_score_}\")\n",
    "\n",
    "print(f\"Cross-validated accuracy : {rf_clf_cv_score}\") \n",
    "print(f\"Mean CV accuracy : {np.round(np.mean(rf_clf_cv_score), 3)}\")\n",
    "\n",
    "print(f\"Test set score : {rf_clf.score(w2v_test, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf_scaled = RandomForestClassifier(oob_score=True)\n",
    "\n",
    "rf_clf_scaled.fit(w2v_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 0.9997917245209664\n",
      "Out-of-Bag Score: 0.8192168841988337\n",
      "Cross-validated accuracy : [0.84206873 0.83234988 0.82089552 0.83200278 0.82743056]\n",
      "Mean CV accuracy : 0.831\n",
      "Test set score : 0.8458761455151347\n"
     ]
    }
   ],
   "source": [
    "rf_clf_scaled_cv_score = cross_val_score(rf_clf_scaled, w2v_train_scaled, Y_train)\n",
    "\n",
    "print(f\"Training Set Accuracy: {rf_clf_scaled.score(w2v_train_scaled, Y_train)}\")\n",
    "print(f\"Out-of-Bag Score: {rf_clf_scaled.oob_score_}\")\n",
    "\n",
    "print(f\"Cross-validated accuracy : {rf_clf_scaled_cv_score}\") \n",
    "print(f\"Mean CV accuracy : {np.round(np.mean(rf_clf_scaled_cv_score), 3)}\")\n",
    "\n",
    "print(f\"Test set score : {rf_clf_scaled.score(w2v_test_scaled, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameter Tuning via Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB The below cell only appears once. The same hyperparameter grid and CV process is used across for all (subsequent) tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Hyperparameter Search Space\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 100, None],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [50, 100, 300]\n",
    "}\n",
    "\n",
    "# Set Cross-Validation Process\n",
    "\n",
    "kfcv = KFold(n_splits=5, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "rf_grid_search = GridSearchCV(estimator = rf_clf, param_grid = param_grid, \n",
    "                              cv = kfcv, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 65.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_f...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=True, random_state=None,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [80, 100, None],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.fit(w2v_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8335177552161672\n",
      "\n",
      "Best parameters:\n",
      "bootstrap: True\n",
      "max_depth: 100\n",
      "max_features: sqrt\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "n_estimators: 300\n"
     ]
    }
   ],
   "source": [
    "# Best Score\n",
    "\n",
    "print(f\"Best Score: {rf_grid_search.best_score_}\", end=\"\\n\"*2)\n",
    "\n",
    "# Best Parameters\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "for k, v in rf_grid_search.best_params_.items():\n",
    "    print(str(k) + \": \" + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Scaled Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "rf_grid_search_w2v_scaled = GridSearchCV(estimator = rf_clf_scaled, param_grid = param_grid, \n",
    "                                         cv = kfcv, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed: 78.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=101, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_f...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=True, random_state=None,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True], 'max_depth': [80, 100, None],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 3, 5],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search_w2v_scaled.fit(w2v_train_scaled, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.8340039145358478\n",
      "\n",
      "Best parameters:\n",
      "bootstrap: True\n",
      "max_depth: 80\n",
      "max_features: sqrt\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "n_estimators: 300\n"
     ]
    }
   ],
   "source": [
    "# Best Score\n",
    "\n",
    "print(f\"Best Score: {rf_grid_search_w2v_scaled.best_score_}\", end=\"\\n\"*2)\n",
    "\n",
    "# Best Parameters\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "for k, v in rf_grid_search_w2v_scaled.best_params_.items():\n",
    "    print(str(k) + \": \" + str(v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
