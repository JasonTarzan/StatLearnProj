{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image  \n",
    "#from pydotplus import *\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import of datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>Economic recovery and national climate pledges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>In this difficult time  it’s hard to connect w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>43</td>\n",
       "      <td>69</td>\n",
       "      <td>The decision to postpone   COP    is unavoidab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>Japan   the world’s fifth largest emitter of g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>How can countries include   NatureBasedSolutio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              username user_handle        date retweets  \\\n",
       "0           0  WWF Climate & Energy  climateWWF  2020-04-28       11   \n",
       "1           1  WWF Climate & Energy  climateWWF  2020-04-22        6   \n",
       "2           2  WWF Climate & Energy  climateWWF  2020-04-01       43   \n",
       "3           3  WWF Climate & Energy  climateWWF  2020-03-30       24   \n",
       "4           4  WWF Climate & Energy  climateWWF  2020-03-30       22   \n",
       "\n",
       "  favorites                                               text  label  \n",
       "0        22  Economic recovery and national climate pledges...      0  \n",
       "1        16  In this difficult time  it’s hard to connect w...      0  \n",
       "2        69  The decision to postpone   COP    is unavoidab...      0  \n",
       "3        30  Japan   the world’s fifth largest emitter of g...      0  \n",
       "4        40  How can countries include   NatureBasedSolutio...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/FelicieBizeul/Desktop/ETUDES/ENSAI/Erasmus/SL/project/Try_bow/climate_change_tweets_sample_to_work_on.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the file which already have been pre-processed, so our datas are cleans of '#' '@' etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the train and test samples of X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape is :  (12066, 8)\n",
      "X_test.shape is :  (5943, 8)\n",
      "Y_train.shape is :  (12066,)\n",
      "Y_test.shape is :  (5943,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, data.label, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"X_train.shape is : \", X_train.shape)\n",
    "print(\"X_test.shape is : \", X_test.shape)\n",
    "print(\"Y_train.shape is : \", Y_train.shape)\n",
    "print(\"Y_test.shape is : \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation of our bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaration of the object with some conditions\n",
    "vectorizer = CountVectorizer(stop_words = 'english', binary=True, min_df = 10)\n",
    "\n",
    "# For create the document term matrix\n",
    "X_train = vectorizer.fit_transform(X_train[\"text\"])\n",
    "X_test = vectorizer.transform(X_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we perform a random forest with random hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 0.995\n",
      "Test set score : 0.907\n"
     ]
    }
   ],
   "source": [
    "rf_random_hp = RandomForestClassifier(n_estimators = 10, random_state=0)\n",
    "rf_random_hp.fit(X_train,Y_train)\n",
    "print(\"Training set score : {:.3f}\".format(rf_random_hp.score(X_train, Y_train)))\n",
    "print(\"Test set score : {:.3f}\".format(rf_random_hp.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy : [0.89478045 0.90886495 0.90637945 0.90803645 0.91300746 0.91052196\n",
      " 0.92288557 0.90298507 0.90961857 0.91127695]\n",
      "Mean CV accuracy : 0.91\n"
     ]
    }
   ],
   "source": [
    "scores_rf_random_hp = cross_val_score(rf_random_hp, X_train, Y_train, cv=10)\n",
    "print(\"CV accuracy : {}\".format(scores_rf_random_hp)) \n",
    "print(\"Mean CV accuracy : {:.2f}\".format(np.mean(scores_rf_random_hp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion d'entraînement' : [[5008   15]\n",
      " [  45 6998]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_training = rf_random_hp.predict(X_train)\n",
    "con_mat_training = confusion_matrix(Y_train,y_pred_training)\n",
    "print(\"Matrice de confusion d'entraînement' : {}\".format(con_mat_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion de test : [[2182  233]\n",
      " [ 319 3209]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_testing = rf_random_hp.predict(X_test)\n",
    "con_mat_testing = confusion_matrix(Y_test,y_pred_testing)\n",
    "print(\"Matrice de confusion de test : {}\".format(con_mat_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we tried to find the best random forest model. We need to import some news packages : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 2000, num = 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 110, num = 11)]\n",
    "max_depth.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [5, 15, 26, 36, 47, 57, 68, 78, 89, 99, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [10, 231, 452, 673, 894, 1115, 1336, 1557, 1778, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the best parameter for a random forest model\n",
    "search_hp = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=0, n_jobs = -1)\n",
    "search_hp.fit(X_train,Y_train) # Be careful it take a little bit of time!!!\n",
    "search_hp.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I would like to try with n_iter = 100 but it was too long to compute, so I tried with n_iter = 1 just to see\n",
    "if it was working, and it was. I will make to program turn this night with 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With n_iter = 1, we have :\n",
    "best_rf_model = RandomForestClassifier(n_estimators = 100 ,min_samples_split= 2,min_samples_leaf= 1,max_features = 'sqrt', max_depth = None ,bootstrap = True,random_state=0)\n",
    "best_rf_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_best_rf_model = cross_val_score(best_rf_model, X_train, Y_train, cv=10)\n",
    "mean_best = np.mean(scores_best_rf_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
