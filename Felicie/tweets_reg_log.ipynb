{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>Economic recovery and national climate pledges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>In this difficult time, it’s hard to connect w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>43</td>\n",
       "      <td>69</td>\n",
       "      <td>The decision to postpone # COP26, is unavoidab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>Japan - the world’s fifth largest emitter of g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>How can countries include # NatureBasedSolutio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username user_handle        date retweets favorites  \\\n",
       "0  WWF Climate & Energy  climateWWF  2020-04-28       11        22   \n",
       "1  WWF Climate & Energy  climateWWF  2020-04-22        6        16   \n",
       "2  WWF Climate & Energy  climateWWF  2020-04-01       43        69   \n",
       "3  WWF Climate & Energy  climateWWF  2020-03-30       24        30   \n",
       "4  WWF Climate & Energy  climateWWF  2020-03-30       22        40   \n",
       "\n",
       "                                                text  label  \n",
       "0  Economic recovery and national climate pledges...      0  \n",
       "1  In this difficult time, it’s hard to connect w...      0  \n",
       "2  The decision to postpone # COP26, is unavoidab...      0  \n",
       "3  Japan - the world’s fifth largest emitter of g...      0  \n",
       "4  How can countries include # NatureBasedSolutio...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>user_handle</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-28</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>Economic recovery and national climate pledges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>In this difficult time, it’s hard to connect w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>43</td>\n",
       "      <td>69</td>\n",
       "      <td>The decision to postpone # COP26, is unavoidab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>Japan - the world’s fifth largest emitter of g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WWF Climate &amp; Energy</td>\n",
       "      <td>climateWWF</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>How can countries include # NatureBasedSolutio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               username user_handle        date retweets favorites  \\\n",
       "0  WWF Climate & Energy  climateWWF  2020-04-28       11        22   \n",
       "1  WWF Climate & Energy  climateWWF  2020-04-22        6        16   \n",
       "2  WWF Climate & Energy  climateWWF  2020-04-01       43        69   \n",
       "3  WWF Climate & Energy  climateWWF  2020-03-30       24        30   \n",
       "4  WWF Climate & Energy  climateWWF  2020-03-30       22        40   \n",
       "\n",
       "                                                text  label  \n",
       "0  Economic recovery and national climate pledges...      0  \n",
       "1  In this difficult time, it’s hard to connect w...      0  \n",
       "2  The decision to postpone # COP26, is unavoidab...      0  \n",
       "3  Japan - the world’s fifth largest emitter of g...      0  \n",
       "4  How can countries include # NatureBasedSolutio...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/FelicieBizeul/Desktop/ETUDES/ENSAI/Erasmus/SL/project/Try_bow/climate_change_tweets_sample.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class : [ 7438 10571]\n",
      "Samples per class : [ 7438 10571]\n"
     ]
    }
   ],
   "source": [
    "print(\"Samples per class : {}\".format(np.bincount(data.label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=data\n",
    "for i in range(data.shape[0]):\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('@', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('http', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('http', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('com', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('twitter', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('€', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('$', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('-', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('_', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('=', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('www', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('1', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('2', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('3', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('4', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('5', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('6', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('7', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('8', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('9', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('0', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('#', ' ')\n",
    "   #data['text'].iloc[i] = data['text'].iloc[i].replace('', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace(' ', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace(';', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace(',', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('!', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('/', ' ')\n",
    "   t['text'].iloc[i] = data['text'].iloc[i].replace('?', ' ')\n",
    "data=t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, data.label, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There is an other way to define those samples with this function :\n",
    "# def simple_split(data, Y, length, split_mark = 0.7):\n",
    "#     if split_mark > 0. and split_mark < 1.0 :\n",
    "#         n = int(split_mark*length)\n",
    "#     else:\n",
    "#          n = int(split_mark)\n",
    "#     X_train = data[:n].copy()\n",
    "#     X_test = data[n:].copy()\n",
    "#     Y_train = Y[:n].copy()\n",
    "#     Y_test = Y[:].copy()\n",
    "#     return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = simple_split(data, data.label, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape is :  (12066, 7)\n",
      "X_train.shape is :  (12066, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape is : \", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape is :  (5943, 7)\n",
      "X_test.shape is :  (5943, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test.shape is : \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train.shape is :  (12066,)\n",
      "Y_train.shape is :  (12066,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_train.shape is : \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test.shape is :  (5943,)\n",
      "Y_test.shape is :  (5943,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Y_test.shape is : \", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation of the object with some conditions\n",
    "vectorizer = CountVectorizer(stop_words = 'english', binary=True, min_df = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For create the document term matrix\n",
    "X_train = vectorizer.fit_transform(X_train[\"text\"])\n",
    "X_test = vectorizer.transform(X_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get all the words\n",
    "features_names = vectorizer.get_feature_names\n",
    "print(features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of features : {}\".format(len(features_names))) # nb of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 20 features :\\n {}\".format(features_names[:20]))\n",
    "print(\"Every 2000th features :\\n {}\".format(features_names[::2000])) # each 2000th features\n",
    "print(\"features :\\n {}\".format(features_names[1000:1050]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.vocabulary_ #to get all words\n",
    "print(\"vocab : {}\".format(len(vocab))) # nb of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the same number of words than with the get features names function, so correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_.get('climate') #to get one specific word or sentence\n",
    "vectorizer.vocabulary_.get('hoax')\n",
    "vectorizer.vocabulary_.get('warming')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef training: [[ 0.37944972  0.39876676 -0.18129163 ... -0.59140365  0.07459763\n",
      "   1.54384626]]\n",
      "Training set score : 0.972\n",
      "Test set score : 0.931\n",
      "Coef training: [[ 0.37944972  0.39876676 -0.18129163 ... -0.59140365  0.07459763\n",
      "   1.54384626]]\n",
      "Training set score : 0.972\n",
      "Test set score : 0.931\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Coef training: {}\".format(logreg.coef_))\n",
    "print(\"Training set score : {:.3f}\".format(logreg.score(X_train, Y_train)))\n",
    "print(\"Test set score : {:.3f}\".format(logreg.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a 3 fold cross validation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy : [0.92192939 0.93262059 0.92640477]\n",
      "Mean CV accuracy : 0.93\n",
      "CV accuracy : [0.92192939 0.93262059 0.92640477]\n",
      "Mean CV accuracy : 0.93\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LogisticRegression(), X_train, Y_train, cv = 3)\n",
    "print(\"CV accuracy : {}\".format(scores)) #Afficher la moyenne des scores\n",
    "print(\"Mean CV accuracy : {:.2f}\".format(np.mean(scores))) #Afficher la moyenne des scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform penalised models (Lasso and Ridge penalties). We can perform Lasso and/or Ridge logistic regression with many values(for exemple using a logarithm scales). And then we can compare the performance of each model using cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score : 1.000\n",
      "Training set score : 1.000\n",
      "Test set score : 0.919\n",
      "Test set score : 0.919\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"Training set score : {:.3f}\".format(rf.score(X_train, Y_train)))\n",
    "print(\"Test set score : {:.3f}\".format(rf.score(X_test, Y_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a 3 fold cross validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy : [0.90651417 0.92068623 0.90651417]\n",
      "Mean CV accuracy : 0.91\n",
      "CV accuracy : [0.90651417 0.92068623 0.90651417]\n",
      "Mean CV accuracy : 0.91\n"
     ]
    }
   ],
   "source": [
    "scores_forest = cross_val_score(rf, X_train, Y_train, cv = 3)\n",
    "print(\"CV accuracy : {}\".format(scores_forest)) #Afficher la moyenne des scores\n",
    "print(\"Mean CV accuracy : {:.2f}\".format(np.mean(scores_forest))) #Afficher la moyenne des scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare each model using ROC curve and Cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
